# Awesome-LLM-IoT-Papers
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
![](https://img.shields.io/github/last-commit/KAIWEILIUCC/Awesome-LLM-IoT-Papers?color=green)


## Table of Contents
- [üìú Surveys](#surveys)
- [üé≤ LLM Agents](#llm-agents) 
- [üöÄ Edge FM](#edge-fm)
- [üîä Sensor Data Understanding](#sensor-data-understanding)
- [üíª Code Generation](#code-generation)
- [üí° Interesting Applications](#interesting-applications)
- [üßë‚Äç‚öïÔ∏è Smart Health](#smart-health)
- [üîó Resources](#resources)

## Surveys
[A Survey of Foundation Models for IoT: Taxonomy and Criteria-Based Analysis](https://arxiv.org/abs/2506.12263).  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2506.12263)

[The role of Large Language Models in addressing IoT challenges: A systematic literature review](https://www.sciencedirect.com/science/article/pii/S0167739X25001244).

[Foundation Models for CPS-IoT: Opportunities and Challenges](https://arxiv.org/abs/2501.16368).  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2501.16368)

[LLMs and IoT: A Comprehensive Survey on Large Language Models and the Internet of Things](https://www.techrxiv.org/users/894996/articles/1271502/master/file/data/LLMs%20and%20IoT_A_Comprehensive_Survey_V2/LLMs%20and%20IoT_A_Comprehensive_Survey_V2.pdf?inline=true).

## LLM Agents
AutoDroid: [LLM-powered Task Automation in Android](https://arxiv.org/abs/2308.15272) (MobiCom 2024)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2308.15272)

MobileGPT: [Augmenting LLM with Human-like App Memory for Mobile Task Automation](https://arxiv.org/abs/2312.03003) (MobiCom 2024)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2312.03003)
[![Star](https://img.shields.io/github/stars/mobilegptsys/MobileGPT.svg?style=social&label=Star)](https://github.com/mobilegptsys/MobileGPT.git)

[Poster: Enabling Agent-centric Interaction on Smartphones with LLM-based UI Reassembling](https://dl.acm.org/doi/10.1145/3643832.3661432) (MobiSys 2024) 


[LLMind: Orchestrating AI and IoT with LLM for Complex Task Execution](https://arxiv.org/abs/2312.09007).  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2312.09007)


[LLMind 2.0: Distributed IoT Automation with Natural Language M2M Communication and Lightweight LLM Agents](https://www.arxiv.org/abs/2508.13920).  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://www.arxiv.org/abs/2508.13920)


TaskSense: [A Translation-like Approach for Tasking Heterogeneous Sensor Systems with LLMs.](https://dl.acm.org/doi/10.1145/3715014.3722070) (SenSys 2025)


[Toward Sensor-In-the-Loop LLM Agent: Benchmarks and Implications.](https://doi.org/10.1145/3715014.3722082) (SenSys 2025)

ContextAgent: [Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions](https://arxiv.org/abs/2505.14668). (NeurIPS 2025)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2505.14668)

SensorMCP: [A Model Context Protocol Server for Custom Sensor Tool Creation](https://guoyunqi.com/assets/pdf/sensormcp-netaisys2025.pdf). (NetAISys 2025)

## Edge FM
MELTing Point: [Mobile Evaluation of Language Transformers](https://arxiv.org/abs/2403.12844) (MobiCom 2024)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2403.12844)

Your Data, Your Model: [A Framework for Training and Deploying Foundational Language Models for Embedded Devices.](https://dl.acm.org/doi/10.1145/3636534.3695901) (MobiCom 2024)


[Federated Black-box Prompt Tuning System for Large Language Models on the Edge.](https://dl.acm.org/doi/10.1145/3636534.3698856) (MobiCom 2024)

[A Framework for Training and Deploying Foundational Language Models for Embedded Sensing.](https://dl.acm.org/doi/10.1145/3636534.3695901) (MobiCom 2024)

EdgeFM: [Leveraging Foundation Model for Open-set Learning on the Edge](https://arxiv.org/abs/2311.10986) (IMWUT 2024)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.10986)


## Sensor Data Understanding
[Improving On-Device LLMs' Sensory Understanding with Embedding Interpolations](https://dl.acm.org/doi/10.1145/3636534.3697456) (MobiCom 2024)

Penetrative AI: [Making LLMs Comprehend the Physical World](https://arxiv.org/abs/2310.09605) (ACL 2024)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2310.09605)

## Code Generation
AutoIOT: [LLM-Driven Automated Natural Language Programming for AIoT Applications](https://arxiv.org/abs/2503.05346) (MobiCom 2025)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2503.05346)
[![Star](https://img.shields.io/github/stars/lemingshen/AutoIOT.svg?style=social&label=Star)](https://github.com/lemingshen/AutoIOT.git)

GPIoT: [Tailoring Small Language Models for IoT Program Synthesis and Development](https://arxiv.org/abs/2503.00686) (SenSys 2025)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2503.00686)
[![Star](https://img.shields.io/github/stars/lemingshen/GPIoT.svg?style=social&label=Star)](https://github.com/lemingshen/GPIoT.git)

CheckMate: [LLM-Powered Approximate Intermittent Computing](https://dl.acm.org/doi/10.1145/3715014.3722056) (SenSys 2025)

## Interesting Applications
TransCompressor: [LLM-Powered Multimodal Data Compression for Smart Transportation](https://arxiv.org/abs/2411.16020)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2411.16020)

Llambda: [An LLM-Empowered Low-Resolution Vision System for On-Device Human Behavior Understanding](https://arxiv.org/pdf/2505.01743)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/pdf/2505.01743)

IoT-LLM: Enhancing Real-World IoT Task Reasoning with Large Language Models (Arxiv) [Paper](https://arxiv.org/abs/2410.02429)


LightLLM: [A Versatile Large Language Model for Predictive Light Sensing](https://arxiv.org/abs/2411.15211) (SenSys 2025)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2411.15211)


FlexiFly: [Interfacing the Physical World with Foundation Models Empowered by Reconfigurable Drone Systems](https://arxiv.org/abs/2403.12853) (SenSys 2025)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2403.12853)


Socialmind: [LLM-based proactive ar social assistive system with human-like perception for in-situ live interactions](https://arxiv.org/abs/2412.04036) (IMWUT 2025)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2412.04036)

TRAMBA: [A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms](https://arxiv.org/abs/2405.01242) (IMWUT 2024)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2405.01242)

[Exploring Foundation Models in Detecting Concerning Daily Functioning in Psychotherapeutic Context Based on Images from Smart Home Devices](https://ieeexplore.ieee.org/abstract/document/10590355) (ACM FMSys 2024)

Sensor2Scene: [Foundation Model-Driven Interactive Realities](https://ieeexplore.ieee.org/abstract/document/10590268) (ACM FMSys 2024)



## Smart Health
SHADE-AD: [An LLM-Based Framework for Synthesizing Activity Data of Alzheimer's Patients.](https://dl.acm.org/doi/10.1145/3715014.3722062) (SenSys 2025)

DrHouse: [An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge](https://arxiv.org/abs/2405.12541) (IMWUT 2024)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2405.12541)

[LLM-based Conversational AI Therapist for Daily Functioning Screening and Psychotherapeutic Intervention via Everyday Smart Devices](https://arxiv.org/abs/2403.10779)  
[![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2403.10779)

## Resources

